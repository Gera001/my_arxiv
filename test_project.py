import os
import json
import time
import logging
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("ArxivMind-Test")

from database import Session, Paper, User
from core_batch import get_semantic_scholar_free, call_qwen_ai_sync
from services import send_daily_emails


def test_database_robustness():
    """æµ‹è¯•æ•°æ®åº“ï¼šéªŒè¯ç”¨æˆ·é‡å¤æ³¨å†Œæ—¶çš„å¥å£®æ€§"""
    logger.info("--- [1/5] æµ‹è¯•æ•°æ®åº“å¥å£®æ€§ ---")
    session = Session()
    test_email = "tester_robust@example.com"
    try:
        # æ¨¡æ‹Ÿç¬¬ä¸€æ¬¡æ³¨å†Œ
        u1 = User(email=test_email, subscribed_categories="AI")
        session.add(u1)
        session.commit()
        logger.info("é¦–æ¬¡æ³¨å†ŒæˆåŠŸ")

        # æ¨¡æ‹Ÿé‡å¤æ³¨å†Œï¼ˆå¥å£®æ€§é€»è¾‘ï¼‰
        existing_user = session.query(User).filter_by(email=test_email).first()
        if existing_user:
            logger.info("æ£€æµ‹åˆ°é‚®ç®±å·²å­˜åœ¨ï¼Œæ­£åœ¨æ‰§è¡Œæ›´æ–°è€Œéæ’å…¥...")
            existing_user.subscribed_categories = "AI, å¤§æ¨¡å‹"
            session.commit()
            logger.info("âœ… æ•°æ®åº“ Upsert é€»è¾‘é€šè¿‡")

        # æ¸…ç†
        session.delete(existing_user)
        session.commit()
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
        session.rollback()
    finally:
        session.close()


def test_semantic_scholar_free():
    """æµ‹è¯•å…è´¹ç‰ˆ Semantic Scholar API"""
    logger.info("\n--- [2/5] æµ‹è¯•å…è´¹ç‰ˆ Semantic Scholar API ---")
    test_arxiv_id = "2305.16300"  # è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„è®ºæ–‡ ID
    data = get_semantic_scholar_free(test_arxiv_id)
    if data and 'citationCount' in data:
        logger.info(f"âœ… API è¿é€šæˆåŠŸ! è®ºæ–‡ {test_arxiv_id} çš„å¼•ç”¨é‡ä¸º: {data['citationCount']}")
    else:
        logger.warning("â“ API æœªè¿”å›æ•°æ®ï¼Œå¯èƒ½æ˜¯è§¦å‘äº†é¢‘ç‡é™åˆ¶æˆ– ID é”™è¯¯")


def test_expert_ai_prompt():
    """æµ‹è¯•ä¸“å®¶çº§æç¤ºè¯ä¸ JSON æ ¼å¼è§£æ"""
    logger.info("\n--- [3/5] æµ‹è¯•ä¸“å®¶çº§ AI æç¤ºè¯ ---")
    test_text = "This paper introduces a new method for scaling Large Language Models using MoE architecture..."
    # æ¨¡æ‹Ÿ core_batch ä¸­çš„ä¸“å®¶ Prompt
    prompt = f"ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ AI ç§‘æ™®ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å†…å®¹å¹¶ä»¥ JSON æ ¼å¼è¿”å›ï¼š{test_text}"

    result_raw = call_qwen_ai_sync(prompt)
    try:
        if isinstance(result_raw, str):
            result = json.loads(result_raw)
        else:
            result = result_raw

        if "popular_science" in result:
            logger.info(f"âœ… AI è§£ææˆåŠŸ! åˆ†ç±»: {result.get('category')}")
            logger.info(f"ç§‘æ™®æ‘˜è¦é¢„è§ˆ: {result.get('popular_science')[:50]}...")
        else:
            logger.error("âŒ AI è¿”å›æ ¼å¼ä¸å®Œæ•´")
    except Exception as e:
        logger.error(f"âŒ AI è§£æå¤±è´¥: {e}")


def test_email_service():
    """æµ‹è¯•é‚®ä»¶å‘é€åŠŸèƒ½"""
    logger.info("\n--- [4/5] æµ‹è¯•é‚®ä»¶æ¨é€æœåŠ¡ ---")
    if not os.getenv("RESEND_API_KEY"):
        logger.error("æœªæ£€æµ‹åˆ° RESEND_API_KEY")
        return

    session = Session()
    test_email = input("è¯·è¾“å…¥ç”¨äºæ¥æ”¶æµ‹è¯•é‚®ä»¶çš„çœŸå®é‚®ç®±: ")
    try:
        # 1. åˆ›å»ºæ¨¡æ‹Ÿè®ºæ–‡
        mock_p = Paper(
            title="AI è‡ªåŠ¨åŒ–æµ‹è¯•è®ºæ–‡",
            category="æµ‹è¯•é¢†åŸŸ",
            popular_science="è¿™æ˜¯ä¸€ç¯‡ AI ç”Ÿæˆçš„æ¨¡æ‹Ÿç§‘æ™®ï¼Œç”¨äºéªŒè¯é‚®ä»¶æ¸²æŸ“ã€‚",
            batch_status="completed",
            url="https://arxiv.org/abs/test"
        )
        session.add(mock_p)

        # 2. åˆ›å»º/æ›´æ–°æµ‹è¯•ç”¨æˆ·
        u = session.query(User).filter_by(email=test_email).first()
        if not u:
            u = User(email=test_email, is_subscribed=True)
            session.add(u)
        else:
            u.is_subscribed = True

        session.commit()

        logger.info(f"æ­£åœ¨å‘é€é‚®ä»¶è‡³ {test_email}...")
        send_daily_emails()
        logger.info("âœ… é‚®ä»¶æŒ‡ä»¤å·²å‘å‡ºï¼Œè¯·æ£€æŸ¥æ”¶ä»¶ç®±")

        # æ¸…ç†
        session.delete(mock_p)
        session.commit()
    except Exception as e:
        logger.error(f"âŒ é‚®ä»¶æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
    finally:
        session.close()


def test_full_integrated_flow():
    """å…¨æµç¨‹å†’çƒŸæµ‹è¯•ï¼šä»æ¨¡æ‹Ÿå…¥åº“åˆ° AI åŒæ­¥å¤„ç†åˆ°é‚®ä»¶"""
    logger.info("\n--- [5/5] å…¨æµç¨‹é›†æˆæµ‹è¯• (é›†æˆæ‰€æœ‰æ–°é€»è¾‘) ---")
    session = Session()
    try:
        # 1. æ¨¡æ‹Ÿè®ºæ–‡å…¥åº“
        paper_title = "é›†æˆæµ‹è¯•è®ºæ–‡_" + str(int(time.time()))
        new_paper = Paper(
            title=paper_title,
            url="https://arxiv.org/test/" + paper_title,
            full_text_tmp="è¿™æ˜¯æ¨¡æ‹Ÿçš„è®ºæ–‡æ­£æ–‡å†…å®¹ï¼Œå…³äº AI æ™ºèƒ½ä½“ï¼ˆAgentï¼‰çš„æœ€æ–°ç ”ç©¶ã€‚",
            batch_status="pending"
        )
        session.add(new_paper)
        session.commit()
        logger.info(f"æ¨¡æ‹Ÿè®ºæ–‡ {paper_title} å·²å­˜å…¥")

        # 2. è°ƒç”¨åŒæ­¥ AI å¤„ç† (ä¸“å®¶ Prompt)
        logger.info("æ­£åœ¨è°ƒç”¨ AI è¿›è¡Œæ·±åº¦åˆ†æ...")
        res = call_qwen_ai_sync(f"æ ‡é¢˜: {new_paper.title}\nå†…å®¹: {new_paper.full_text_tmp}")

        if res:
            data = json.loads(res) if isinstance(res, str) else res
            new_paper.category = data.get('category', 'AI')
            new_paper.popular_science = data.get('popular_science', '')
            new_paper.analysis_json = data
            new_paper.batch_status = "completed"
            session.commit()
            logger.info("âœ… AI å¤„ç†å®Œæˆå¹¶å›å¡«æ•°æ®åº“")

            # 3. è§¦å‘é‚®ä»¶
            send_daily_emails()
            logger.info("âœ… å…¨æµç¨‹é›†æˆæµ‹è¯•æŒ‡ä»¤å®Œæˆ")

        # æ¸…ç†æµ‹è¯•æ•°æ®
        session.delete(new_paper)
        session.commit()
    except Exception as e:
        logger.error(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        session.rollback()
    finally:
        session.close()


if __name__ == "__main__":
    logger.info("ğŸš€ å¼€å§‹ ArxivMind å¥å£®æ€§å…¨å¥—æµ‹è¯•")

    # ä½ å¯ä»¥æ ¹æ®éœ€è¦æ³¨é‡Šæ‰éƒ¨åˆ†æµ‹è¯•
    test_database_robustness()
    test_semantic_scholar_free()
    test_expert_ai_prompt()
    test_email_service()
    test_full_integrated_flow()

    logger.info("\nâœ¨ æ‰€æœ‰æµ‹è¯•æ‰§è¡Œå®Œæ¯•")